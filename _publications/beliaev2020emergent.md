---
title: "Emergent Correlated Equilibrium Through Synchronized Exploration"
collection: publications
permalink: /publication/beliaev2020emergent
excerpt: 'Correlated equilibria strategies can be more prosocial, as they can achieve a larger expected sum of rewards compared to pure-strategy Nash equilibria. However, it can be difficult to reach correlated equilibria in multi-agent environments due to non-stationarity. We propose Synchronized $$\epsilon$$-Greedy Exploration, which builds on the commonly-used $$\epsilon$$-greedy exploration, and therefore can be generalized to stochastic games and used in any off-policy learning algorithm.'
date: 2020-07-01
venue: 'RSS 2020 Workshop on Emergent Behavior in Human-Robot Systems'
paperurl: ''
citation: 'M. Beliaev*, <b>W. Wang*<b>, D. Lazar, E. Biyik, D. Sadigh, R. Pedarsani. Emergent Correlated Equilibrium Through Synchronized Exploration. RSS 2020 Workshop on Emergent Behavior in Human-Robot Systems, July 2020.'
---
Correlated equilibria strategies can be more prosocial, as they can achieve a larger expected sum of rewards compared to pure-strategy Nash equilibria. However, it can be difficult to reach correlated equilibria in multi-agent environments due to non-stationarity. We propose Synchronized $$\epsilon$$-Greedy Exploration, which builds on the commonly-used $$\epsilon$$-greedy exploration, and therefore can be generalized to stochastic games and used in any off-policy learning algorithm.

[Download paper here](http://woodywang153.github.io/files/papers/beliaev2020emergent.pdf)

<!-- Recommended citation: Your Name, You. (2010). "Paper Title Number 2." <i>Journal 1</i>. 1(2). -->